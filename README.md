# LangGraph â†’ BigQuery â†’ Streamlit Dashboard Demo ðŸš€

_A full Genâ€‘AI analytics stack in < 200 lines of Python_

---

## ðŸ“Š What it does

| Stage           | Action                                                                |
| --------------- | --------------------------------------------------------------------- |
| **1 Prompt**    | You type a plainâ€‘English business question                            |
| **2 LLM**       | GPTâ€‘4o (default) / Gemini / Llama 3 writes governed **BigQuery SQL**  |
| **3 Warehouse** | Query runs, results stream into a **pandas DataFrame**                |
| **4 LLM**       | Model autogenerates a polished **Streamlit** dashboard                |
| **5 Artifacts** | `dashboard_app.py`, `result.csv`, `query.sql` are saved (gitâ€‘ignored) |

---

## âœ¨ Features

- Governed SQL generation (datasetâ€‘whitelist)
- Handles Driveâ€‘backed Sheets (adds Drive scope automatically)
- Oneâ€‘click proâ€‘grade dashboard (KPI cards, Agâ€‘Grid, autoâ€‘charts, darkâ€‘mode toggle)
- Pluggable LLM (GPTâ€‘4o, Gemini 1.5 Pro, Groq Llama 3)
- CIâ€‘friendly artifactsâ€”just hook the "mock Git push" step

---

## ðŸ—ºï¸ Repo layout

```text
.
â”œâ”€â”€ langgraph_streamlit_dashboard.py   â† main script
â”œâ”€â”€ dashboard_app.py                  â† generated Streamlit app (ignored)
â”œâ”€â”€ result.csv                         â† query result (ignored)
â”œâ”€â”€ query.sql                          â† generated SQL (ignored)
â”œâ”€â”€ .env.example                       â† template for secrets
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ðŸ› ï¸ Quick start

### 1 Â· Clone & install

```bash
git clone https://github.com/yourâ€‘org/genaiâ€‘bqâ€‘dashboard.git
cd genaiâ€‘bqâ€‘dashboard
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

### 2 Â· Create Google Cloud credentials (oneâ€‘time)

| Step                           | Console navigation                          | Notes                                                               |
| ------------------------------ | ------------------------------------------- | ------------------------------------------------------------------- |
| **a Create a service account** | **IAM & Admin â†’ Service Accounts â†’ Create** | Name it `genai-dashboard-svc`                                       |
| **b Grant roles**              | Same wizard â†’ **Roles**                     | _BigQuery Job User_ + _BigQuery Data Viewer_ (or datasetâ€‘level ACL) |
| **c Download a JSON key**      | **Keys â†’ Add key â†’ JSON**                   | Saves `yourâ€‘svcâ€‘acctâ€‘key.json`                                      |
| **d Enable APIs**              | **APIs & Services â†’ Library**               | Turn on **BigQuery API** **and** **Google Drive API**               |

> **Why Drive API?** If any BigQuery table is an external Google Sheet, BigQuery fetches rows via Drive.

### 3 Â· (If using Sheets) share them with the service account

Open each Sheet â†’ **Share** â†’ add `yourâ€‘svcâ€‘acct@â€¦iam.gserviceaccount.com` with **Viewer** access.

### 4 Â· Fill in `.env`

```dotenv
# ---- .env  (never commit this!) ----
# LLM keys
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=...
GROQ_API_KEY=...

# Google Cloud
GOOGLE_APPLICATION_CREDENTIALS=/absolute/path/yourâ€‘svcâ€‘acctâ€‘key.json
BQ_PROJECT_ID=your-gcp-project          # defaults to key's project
BQ_DATASET=analytics                    # dataset the LLM may query
```

### 5 Â· Run the generator

```bash
python langgraph_streamlit_dashboard.py
# Prompt appears, e.g.:
#   Which channels drive the highest LTV customers last quarter?
```

### 6 Â· Launch Streamlit

```bash
streamlit run dashboard_app.py
```

Visit **[http://localhost:8501](http://localhost:8501)**â€”explore filters, charts, KPI cards.

---

## ðŸ”‘ How authentication works

```python
from google.oauth2 import service_account
creds = service_account.Credentials.from_service_account_file(
    KEY_PATH,
    scopes=[
        "https://www.googleapis.com/auth/cloud-platform",  # BigQuery
        "https://www.googleapis.com/auth/drive",           # Sheets external tables
    ],
)
client = bigquery.Client(project=PROJECT_ID, credentials=creds)
```

- **Explicit key path**â€”never falls back to local gcloud creds.
- **Drive scope**â€”BigQuery can read Google Sheets.
- **`.gitignore` blocks `*.json` & `.env*`**â€”keys stay local.

---

## ðŸ¤– Switching LLMs

Unâ€‘comment the block you want in `langgraph_streamlit_dashboard.py`:

```python
# GPTâ€‘4o (default)
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.0)

# Gemini 1.5 Pro
# from langchain_google_genai import ChatGoogleGenerativeAI as ChatLLM
# llm = ChatLLM(model="gemini-1.5-pro-latest",
#               google_api_key=os.getenv("GOOGLE_API_KEY"),
#               temperature=0.0)

# Groq Llamaâ€‘3 70B
# from langchain_groq import ChatGroq
# llm = ChatGroq(model_name="llama3-70b-8192",
#                groq_api_key=os.getenv("GROQ_API_KEY"),
#                temperature=0.0)
```

---

## ðŸ©¹ Common errors & fixes

| Error                            | Likely cause                                                   | Fix                                                               |
| -------------------------------- | -------------------------------------------------------------- | ----------------------------------------------------------------- |
| **`403 accessDenied`** (Sheets)  | Sheet not shared â€¢ Drive API disabled â€¢ creds lack Drive scope | Share sheet â†’ enable Drive API â†’ ensure scope list includes Drive |
| **`BigQuery Job User` missing**  | Service account lacks role                                     | Grant _BigQuery Job User_ in IAM                                  |
| **LLM 429 / insufficient_quota** | Free tier exhausted                                            | Wait 24 h, switch model, or add billing cap                       |
