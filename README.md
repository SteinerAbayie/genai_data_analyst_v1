Hereâ€™s the **entire README in one block**â€”copyâ€‘paste it into a file namedâ€¯`README.md`.

````markdown
<!-- README.md -->

# LangGraphÂ â†’Â BigQueryÂ â†’Â Streamlit Dashboard DemoÂ ğŸš€  
_A full Genâ€‘AI analytics stack in <â€¯200Â lines of Python_

---

## ğŸ“ŠÂ What it does

| Stage | Action |
|-------|--------|
| **1Â Prompt** | You type a plainâ€‘English business question |
| **2Â LLM** | GPTâ€‘4oÂ (default)â€¯/â€¯Geminiâ€¯/â€¯LlamaÂ 3 writes governed **BigQueryâ€¯SQL** |
| **3Â Warehouse** | Query runs, results stream into a **pandasâ€¯DataFrame** |
| **4Â LLM** | Model autogenerates a polished **Streamlit** dashboard |
| **5Â Artifacts** | `dashboard_app.py`, `result.csv`, `query.sql` are saved (gitâ€‘ignored) |

---

## âœ¨Â Features

* Governed SQL generation (datasetâ€‘whitelist)  
* Handles Driveâ€‘backed Sheets (adds Drive scope automatically)  
* Oneâ€‘click proâ€‘grade dashboard (KPI cards, Agâ€‘Grid, autoâ€‘charts, darkâ€‘mode toggle)  
* Pluggable LLM (GPTâ€‘4o, Geminiâ€¯1.5â€¯Pro, GroqÂ Llamaâ€¯3)  
* CIâ€‘friendly artifactsâ€”just hook the â€œmockÂ Git pushâ€ step

---

## ğŸ—ºï¸Â Repo layout

```text
.
â”œâ”€â”€ langgraph_streamlit_dashboard.py   â† main script
â”œâ”€â”€ dashboard_app.py                  â† generated Streamlit app (ignored)
â”œâ”€â”€ result.csv                         â† query result (ignored)
â”œâ”€â”€ query.sql                          â† generated SQL (ignored)
â”œâ”€â”€ .env.example                       â† template for secrets
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
````

---

## ğŸ› ï¸Â QuickÂ start

### 1Â Â·Â Clone & install

```bash
git clone https://github.com/yourâ€‘org/genaiâ€‘bqâ€‘dashboard.git
cd genaiâ€‘bqâ€‘dashboard
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

### 2Â Â·Â Create GoogleÂ Cloud credentials (oneâ€‘time)

| Step                           | Console navigation                          | Notes                                                               |
| ------------------------------ | ------------------------------------------- | ------------------------------------------------------------------- |
| **aÂ Create a service account** | **IAMÂ &Â Admin â†’â€¯Service Accounts â†’â€¯Create** | Name it `genai-dashboard-svc`                                       |
| **bÂ Grant roles**              | Same wizard â†’â€¯**Roles**                     | *BigQuery JobÂ User*Â +Â *BigQuery DataÂ Viewer* (or datasetâ€‘level ACL) |
| **cÂ Download a JSON key**      | **Keys â†’â€¯Add key â†’â€¯JSON**                   | Saves `yourâ€‘svcâ€‘acctâ€‘key.json`                                      |
| **dÂ Enable APIs**              | **APIsÂ &Â Services â†’â€¯Library**               | Turn on **BigQuery API** **and** **Google Drive API**               |

> **Why Drive API?** If any BigQuery table is an external GoogleÂ Sheet, BigQuery fetches rows via Drive.

### 3Â Â·Â (If using Sheets) share them with the service account

Open each Sheet â†’â€¯**Share** â†’ add `yourâ€‘svcâ€‘acct@â€¦iam.gserviceaccount.com` with **Viewer** access.

### 4Â Â·Â Fill in `.env`

```dotenv
# ---- .env  (never commit this!) ----
# LLM keys
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=...
GROQ_API_KEY=...

# GoogleÂ Cloud
GOOGLE_APPLICATION_CREDENTIALS=/absolute/path/yourâ€‘svcâ€‘acctâ€‘key.json
BQ_PROJECT_ID=your-gcp-project          # defaults to keyâ€™s project
BQ_DATASET=analytics                    # dataset the LLM may query
```

### 5Â Â·Â Run the generator

```bash
python langgraph_streamlit_dashboard.py
# Prompt appears, e.g.:
#   Which channels drive the highest LTV customers last quarter?
```

### 6Â Â·Â Launch Streamlit

```bash
streamlit run dashboard_app.py
```

Visit \*\*[http://localhost:8501\*\*â€”explore](http://localhost:8501**â€”explore) filters, charts, KPI cards.

---

## ğŸ”‘Â How authentication works

```python
from google.oauth2 import service_account
creds = service_account.Credentials.from_service_account_file(
    KEY_PATH,
    scopes=[
        "https://www.googleapis.com/auth/cloud-platform",  # BigQuery
        "https://www.googleapis.com/auth/drive",           # Sheets external tables
    ],
)
client = bigquery.Client(project=PROJECT_ID, credentials=creds)
```

* **Explicit key path**â€”never falls back to local gcloud creds.
* **Drive scope**â€”BigQuery can read GoogleÂ Sheets.
* **`.gitignore` blocks `*.json` & `.env*`**â€”keys stay local.

---

## ğŸ¤–Â Switching LLMs

Unâ€‘comment the block you want in `langgraph_streamlit_dashboard.py`:

```python
# GPTâ€‘4oÂ (default)
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.0)

# GeminiÂ 1.5Â Pro
# from langchain_google_genai import ChatGoogleGenerativeAI as ChatLLM
# llm = ChatLLM(model="gemini-1.5-pro-latest",
#               google_api_key=os.getenv("GOOGLE_API_KEY"),
#               temperature=0.0)

# GroqÂ Llamaâ€‘3Â 70B
# from langchain_groq import ChatGroq
# llm = ChatGroq(model_name="llama3-70b-8192",
#                groq_api_key=os.getenv("GROQ_API_KEY"),
#                temperature=0.0)
```

---

## ğŸ©¹Â Common errors & fixes

| Error                             | Likely cause                                                   | Fix                                                               |
| --------------------------------- | -------------------------------------------------------------- | ----------------------------------------------------------------- |
| **`403 accessDenied`** (Sheets)   | Sheet not shared â€¢ Drive API disabled â€¢ creds lack Drive scope | Share sheet â†’ enable Drive API â†’ ensure scope list includes Drive |
| **`BigQuery Job User` missing**   | Service account lacks role                                     | Grant *BigQuery JobÂ User* in IAM                                  |
| **LLM 429 / insufficient\_quota** | Free tier exhausted                                            | Wait 24â€¯h, switch model, or add billing cap                       |

---

## ğŸ›¡ï¸Â Security checklist

1. `.gitignore` blocks **all `*.json`** and `.env*` files.
2. Rotate keys if you accidentally commit them (and purge history with BFG).
3. Set a **budget cap** in each LLM console while testing.
4. Use leastâ€‘privilege rolesâ€”datasetâ€‘level permissions where possible.

---
